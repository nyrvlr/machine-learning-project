# -*- coding: utf-8 -*-
"""modelo_classificacao.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19q_4RJYoS-SSGihKIBUkMQtM57Zf7CtO

# Imports
Importando bibliotecas necessárias
"""

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler, LabelEncoder
import matplotlib.pyplot as plt
from sklearn.utils import resample

"""# Carregando os dados"""

# Carregar os dados
dados = pd.read_csv('v4.csv')

dados.columns

"""## Selecionando e tratando colunas"""

# Selecionar colunas relevantes
colunas_relevantes = [
    'TP_SEXO', 'TP_ESTADO_CIVIL','TP_COR_RACA','TP_NACIONALIDADE','TP_ESCOLA','TP_ENSINO', 'TP_NACIONALIDADE',
    'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC',
    'TP_ANO_CONCLUIU', 'NU_NOTA_MT', 'NU_NOTA_REDACAO', 'MEDIA_NOTAS', 'STATUS', 'Q001', 'Q002', 'Q003' , 'Q004', 'Q005',
    'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014',
    'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q022', 'Q024', 'Q025'
]
dados = dados[colunas_relevantes]

# Tratar valores ausentes
dados.fillna(0, inplace=True)

dados['TP_SEXO'] = dados['TP_SEXO'].astype('category').cat.codes
dados['STATUS'] = dados['STATUS'].astype('category').cat.codes
dados['Q003'] = dados['Q003'].astype('category').cat.codes
dados['Q004'] = dados['Q004'].astype('category').cat.codes
dados['Q025']= dados['Q025'].astype('category').cat.codes

dados['STATUS'].value_counts()

"""# Balanceando a amostra"""

# Separar classes
dados_reprovados = dados[dados['STATUS'] == 1]  # Classe REPROVADO
dados_aprovados = dados[dados['STATUS'] == 0]  # Classe APROVADO

# Undersampling dos reprovados
dados_reprovados_downsampled = resample(
    dados_reprovados,
    replace=False,  # Não permite duplicação
    n_samples=len(dados_aprovados),  # Igual ao número de aprovados
    random_state=42
)

# Combinar novamente as classes balanceadas
dados_balanceados = pd.concat([dados_reprovados_downsampled, dados_aprovados])

dados_balanceados['STATUS'].value_counts()

dados_balanceados.head(5)

dados_balanceados.dtypes

dados_numericos = dados_balanceados.select_dtypes(include=['float64', 'int64', 'int8'])

"""# Normalizando os dados
A normalização é necessária para que todas as colunas tenham o mesmo peso no cálculo de k-means
"""

# normalizando os dados para que todas as colunas tenham o mesmo peso no cálculo
scaler = StandardScaler()
dados_numericos_normalizados = scaler.fit_transform(dados_numericos)

# Transformar de volta em DataFrame, se necessário:
dados_normalizados_df = pd.DataFrame(dados_numericos_normalizados, columns=dados_numericos.columns)

dados_normalizados_df.head(5)

"""# K-means - Método do Cotovelo"""

# Testar diferentes valores de k para o método cotovelo
inertia = []
k_values = range(1, 11)  # Testar k de 1 a 10

for k in k_values:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(dados_normalizados_df)
    inertia.append(kmeans.inertia_)

# Plotar o gráfico do cotovelo
plt.figure(figsize=(8, 5))
plt.plot(range(1, 11), inertia, marker='o')
plt.xlabel('Número de Clusters')
plt.ylabel('Inércia')
plt.title('Método do Cotovelo')
plt.show()

## célula para o método da silhueta

#import matplotlib.pyplot as plt
#from sklearn.cluster import KMeans
#from sklearn.metrics import silhouette_score
#from sklearn.preprocessing import StandardScaler

## Testar diferentes valores de k para o método da silhueta
#silhouette_scores = []
#k_values = range(2, 6)  # Testar k de 2 a 10
#for k in k_values:
#    kmeans = KMeans(n_clusters=k, random_state=42)
#    kmeans.fit(dados_normalizados_df)
#    cluster_labels = kmeans.labels_
#    score = silhouette_score(dados_normalizados_df, cluster_labels)
#    silhouette_scores.append(score)

## Plotar o gráfico da pontuação da silhueta
#plt.figure(figsize=(8, 5))
#plt.plot(k_values, silhouette_scores, marker='o')
#plt.xlabel('Número de clusters (k)')
#plt.ylabel('Pontuação da Silhueta')
#plt.title('Método da Silhueta')
#plt.grid(True)
#plt.show()

## Exibir o melhor k
#melhor_k = k_values[np.argmax(silhouette_scores)]
#print(f"O melhor número de clusters (k) é: {melhor_k}")

kmeans = KMeans(n_clusters=7, random_state=42)
clusters = kmeans.fit_predict(dados_normalizados_df)

"""# Adicionando os clusters ao dataset"""

dados_balanceados['cluster'] = clusters

dados_balanceados.to_csv('dados_com_clusters.csv', index=False)

dados_balanceados.head(5)

print(dados_balanceados['cluster'].value_counts(normalize=True))  # verificando quantos alunos em cada cluster

"""# Analisando os Clusters"""

# Comparar clusters em relação à variável-alvo
df_medias = dados_balanceados.groupby('cluster').mean()

#colunas consideradas
colunas = ['TP_COR_RACA', 'TP_ESCOLA', 'TP_ENSINO', 'TP_DEPENDENCIA_ADM_ESC',
       'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC', 'TP_ANO_CONCLUIU', 'Q001',
       'Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010',
       'Q011', 'Q012', 'Q013', 'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019',
       'Q022', 'Q024', 'Q025']

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Verificar a contagem de cada raça por cluster
distribuicao_racial = dados_balanceados.groupby(['cluster', 'TP_COR_RACA']).size().reset_index(name='count')

# Plotar gráfico de barras
plt.figure(figsize=(10, 6))
sns.barplot(data=distribuicao_racial, x='cluster', y='count', hue='TP_COR_RACA', palette='viridis')
plt.title('Distribuição Racial por Cluster')
plt.xlabel('Cluster')
plt.ylabel('Contagem')
plt.legend(title='Cor/Raça')
plt.show()

# Verificar a contagem do tipo de escola por cluster
tipo_escola = dados_balanceados.groupby(['cluster', 'TP_ESCOLA']).size().reset_index(name='count')

# Plotar gráfico de barras
plt.figure(figsize=(10, 6))
sns.barplot(data=tipo_escola, x='cluster', y='count', hue='TP_ESCOLA', palette='muted')
plt.title('Prevalência de Tipo de Escola por Cluster')
plt.xlabel('Cluster')
plt.ylabel('Contagem')
plt.legend(title='Tipo de Escola')
plt.show()

# Verificar a contagem da dependência administrativa por cluster
dependencia_adm = dados_balanceados.groupby(['cluster', 'TP_DEPENDENCIA_ADM_ESC']).size().reset_index(name='count')

# Plotar gráfico de barras
plt.figure(figsize=(10, 6))
sns.barplot(data=dependencia_adm, x='cluster', y='count', hue='TP_DEPENDENCIA_ADM_ESC', palette='pastel')
plt.title('Dependência Administrativa das Escolas por Cluster')
plt.xlabel('Cluster')
plt.ylabel('Contagem')
plt.legend(title='Dependência Administrativa')
plt.show()

# Verificar a contagem da localização das escolas por cluster
localizacao_esc = dados_balanceados.groupby(['cluster', 'TP_LOCALIZACAO_ESC']).size().reset_index(name='count')

# Plotar gráfico de barras
plt.figure(figsize=(10, 6))
sns.barplot(data=localizacao_esc, x='cluster', y='count', hue='TP_LOCALIZACAO_ESC', palette='cool')
plt.title('Localização das Escolas por Cluster')
plt.xlabel('Cluster')
plt.ylabel('Contagem')
plt.legend(title='Localização')
plt.show()

# Verificar a contagem da situação de funcionamento das escolas por cluster
sit_func = dados_balanceados.groupby(['cluster', 'TP_SIT_FUNC_ESC']).size().reset_index(name='count')

# Plotar gráfico de barras
plt.figure(figsize=(10, 6))
sns.barplot(data=sit_func, x='cluster', y='count', hue='TP_SIT_FUNC_ESC', palette='Set2')
plt.title('Situação de Funcionamento das Escolas por Cluster')
plt.xlabel('Cluster')
plt.ylabel('Contagem')
plt.legend(title='Situação de Funcionamento')
plt.show()

# Verificar a contagem de renda familiar por cluster
renda_familiar = dados_balanceados.groupby(['cluster', 'Q006']).size().reset_index(name='count')

# Plotar gráfico de barras para renda familiar por cluster
plt.figure(figsize=(12, 6))
sns.barplot(data=renda_familiar, x='cluster', y='count', hue='Q006', palette='coolwarm')
plt.title('Distribuição de Renda Familiar (Q006) por Cluster')
plt.xlabel('Cluster')
plt.ylabel('Contagem')
plt.legend(title='Renda Familiar', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# Ocupação do pai
ocupacao_pai = dados_balanceados.groupby(['cluster', 'Q001']).size().reset_index(name='count')
plt.figure(figsize=(12, 6))
sns.barplot(data=ocupacao_pai, x='cluster', y='count', hue='Q001', palette='Set2')
plt.title('Ocupação do Pai (Q001) por Cluster')
plt.xlabel('Cluster')
plt.ylabel('Contagem')
plt.legend(title='Ocupação do Pai', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# Ocupação da mãe
ocupacao_mae = dados_balanceados.groupby(['cluster', 'Q002']).size().reset_index(name='count')
plt.figure(figsize=(12, 6))
sns.barplot(data=ocupacao_mae, x='cluster', y='count', hue='Q002', palette='Set3')
plt.title('Ocupação da Mãe (Q002) por Cluster')
plt.xlabel('Cluster')
plt.ylabel('Contagem')
plt.legend(title='Ocupação da Mãe', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""# Preparando Dados para Treinamento"""

# separando os dados em x (características) e y (alvo)
x = dados_balanceados.drop(columns=['STATUS', 'cluster', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_NACIONALIDADE',
                                    'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC',
                                    'NU_NOTA_MT', 'NU_NOTA_REDACAO', 'MEDIA_NOTAS'])  # colunas que foram excluídas e não vão ser usadas como features
y = dados_balanceados['STATUS']

x.columns

# célula para separar dados de treino e teste
from sklearn.model_selection import train_test_split

# treino e teste
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y) #o stratify = y mantém o equilíbrio entre as classes

# treino e validação (feita depois do teste, como segunda avaliação)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

#célula para verificar correlação

#correlations = pd.concat([X_train, y_train], axis=1).corr()
#print(correlations['STATUS'].sort_values(ascending=False))

# verificando se há dados que pertencem tanto ao grupo de treino quanto ao grupo de teste. o resultado aqui deve ser vazio
print(set(X_train.index).intersection(set(X_test.index)))

#treinando o modelo com árvore de decisão
from sklearn.tree import DecisionTreeClassifier

clf = DecisionTreeClassifier(min_samples_split=10, min_samples_leaf=5, random_state=42)
clf.fit(X_train, y_train)

#célula para mostrar a árvore de decisão gerada

#from sklearn.tree import export_text
#tree_rules = export_text(clf, feature_names=list(X_train.columns))
#print(tree_rules)

"""# Avaliando o Modelo"""

#avaliando o modelo
from sklearn.metrics import classification_report

y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))

#sendo X_val o conjunto de validação, aqui avaliamos o modelo com esse conjunto
y_val_pred = clf.predict(X_val)

print(classification_report(y_val, y_val_pred))